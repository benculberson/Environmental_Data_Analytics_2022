---
title: "Lab 4: Data Wrangling"
author: "Environmental Data Analytics | John Fay and Luana Lima | Developed by Kateri Salk"
date: "Spring 2022"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: inline
---

## Objectives
1- Answer questions on M3/A3
2- Answer questions on M4
3- Practice wrangling datasets with dplyr functions

## Set up your session

Today we will work with a dataset from the [North Temperate Lakes Long-Term Ecological Research Station](https://lter.limnology.wisc.edu/about/overview). The NTL-LTER is located in the boreal zone in northern Wisconsin, USA. We will use the [chemical and physical limnology dataset](https://lter.limnology.wisc.edu/content/cascade-project-north-temperate-lakes-lter-core-data-physical-and-chemical-limnology-1984), running from 1984-2016. 

Opening discussion: why might we be interested in long-term observations of temperature, oxygen, and light in lakes?

> Add notes here: 

```{r, message = FALSE}
getwd()
#install.packages(tidyverse)
library(tidyverse)
#install.packages(lubridate)
library(lubridate)
NTL.phys.data <- read.csv("../Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv", stringsAsFactors = TRUE)

class(NTL.phys.data$sampledate)
# Format sampledate as date, remember this is how we read in the dates, we specify the format to help
NTL.phys.data$sampledate <- as.Date(NTL.phys.data$sampledate, format = "%m/%d/%y")
class(NTL.phys.data$sampledate) #just to check
```


## Filter

Filtering allows us to choose certain rows (observations) in our dataset.

```{r}
#we need to know what class the data is to know how to filter it 
class(NTL.phys.data$lakeid) #factor
class(NTL.phys.data$depth) #numeric

# dplyr filtering
NTL.phys.data.surface <- filter(NTL.phys.data, depth == 0) #remember, filter() is for rows of a specified column

# Choose multiple conditions to filter
summary(NTL.phys.data$lakename)
NTL.phys.data.PeterPaul <- filter(NTL.phys.data, lakename %in% c("Paul Lake", "Peter Lake"))
#we had used a "|" symbol to filter the lakes in the module
#here we use a different way to filter
#remember c() brings together vectors 


# Choose a range of conditions of a numeric or integer variable
summary(NTL.phys.data$daynum)
NTL.phys.data.JunethruOctober <- filter(NTL.phys.data, daynum %in% c(152:304))
#look this new way of filtering is perfect for using numbers to slice rows


# Exercise 1: 
# filter NTL.phys.data for the year 1999
# what code do you need to use, based on the class of the variable?
NTL.phys.data.1999 <- filter(NTL.phys.data, year4 == 1999)
NTL.phys.data.1999


# Exercise 2: 
# filter NTL.phys.data for Tuesday Lake from 1990 through 1999.
NTL.phys.data.1990_1999 <- filter(NTL.phys.data, year4 > 1989 & year4 < 2000)
NTL.phys.data.1990_1999.Tuesday <- filter(NTL.phys.data.1990_1999, lakename == "Tuesday Lake")
NTL.phys.data.1990_1999.Tuesday


#also a way to do this:
#NTL.phys.data.Tuesday <- filter(NTL.phys.data, lakename == "Tuesday Lake")
#NTL.phys.data.Tuesday.1990to1999 <- filter(NTL.phys.data.Tuesday, year4 %in% c(1990:1999))
#NTL.phys.data.Tuesday.1990to1999
#notice in this one, using the %in%, the c() function indexes by year value not the row number


```
Question: Why don't we filter using row numbers?

> Answer: Because then we would literally have to hunt down the exact row number where the date changes, that would totally suck

## Pipes

Pipe is another method to wrangle datasets that looks cleaner and is easier to read.  We designate a pipe with `%>%`. A good way to think about the function of a pipe is with the word "then." 

Let's say we want to take our raw dataset (NTL.phys.data), *then* filter the data for Peter and Paul lakes, *then* select temperature and observation information, and *then* add a column for temperature in Fahrenheit: 

```{r}
NTL.phys.data.processed <- 
  NTL.phys.data %>%
  filter(lakename == "Paul Lake" | lakename == "Peter Lake") %>%
  select(lakename, sampledate:temperature_C) %>%
  mutate(temperature_F = (temperature_C*9/5) + 32)

#Exercise 3: Using a pipe filter NTL.phys.data for Tuesday Lake from 1990 through 1999 only for July 
NTL.phys.data.July_1990to1999 <- 
  NTL.phys.data %>%
  filter(lakename == "Tuesday Lake") %>%
  filter(year4 >=1990 & year4 <= 1999) %>%
  filter(month(sampledate) == 7)
    
#could've also just mutated the the sampledate column and then filtered that column for == 7
#we did a simply cuter way
    

#Exercise 4: Using the data from part 3, a pipe and the summarise() function find the mean surface temperature (hints: you will need to add another filter for depth==0). Make sure you eliminate NAs before computing the means
NTL.phys.data.July_1990to1999_mean <-
  NTL.phys.data.July_1990to1999 %>%
  filter(depth == 0) %>%
  subset(!is.na(temperature_C)) %>%
  summarise(mean = mean(temperature_C)) #remember, we want the mean of the temperature_C

NTL.phys.data.July_1990to1999_mean #this will be in celsius
  
```

## Gather and Spread

For gather we will use `pivot_longer` and for spread we will use `pivot_wider`.

```{r}
#Exercise 5: gather irradiance data (measured in the water column and measured on the deck of the sampling boat) into one column using pivot_longer
#there should be many more rows than we had before
NTL.phys.data.gather <- pivot_longer(NTL.phys.data, irradianceWater:irradianceDeck, names_to = "Location", values_to = "Irradiance")
NTL.phys.data.gather <- subset(NTL.phys.data.gather, !is.na(Irradiance))


#Exercise 6: spread temperatureC into more than one column based on the depth
#there should now be many more columns than we had before
NTL.phys.data.spread <- pivot_wider(NTL.phys.data.gather, names_from = depth, values_from = temperature_C)

```

